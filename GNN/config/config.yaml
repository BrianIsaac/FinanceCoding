# Top-level Hydra fix to silence the warning
defaults:
  - _self_

# ---------------- data ----------------
data:
  raw_dir: raw
  processed_dir: processed
  returns_daily: processed/returns_daily.parquet
  labels_dir: processed/labels
  graph_dir: ${paths.graph_dir}     # used by trainer; points to paths.graph_dir
  calendar:
    align: union
    ffill_limit: 5
    min_history_days: 252  # first usable rebalance after this much history

# ---------------- graph build ----------------
graph:
  window_days: 252
  expanding: false
  min_overlap: 126
  rebalance: monthly          # {monthly, quarterly, ...}
  calendar: month_end         # last trading day of calendar period
  method: correlation
  graph_filter: tmfg          # {tmfg, mst, knn, threshold}
  edge_attr: [corr, strength, sign]
  dtype: float32

  tmfg:
    keep_n_edges: auto        # TMFG auto = 3*(N-2) edges

  mst:
    use_absolute_corr: true   # MST on |rho| for stability

  knn:
    k: 8

  threshold:
    abs_corr: 0.30

  features:
    use: [ret_1m, ret_3m, ret_6m, vol_3m, vol_6m, mom_12m, turnover_3m, size]
    winsorize:
      method: mad
      c: 3.5
      q_low: 0.01
      q_high: 0.99
    standardize: zscore
    impute: median

# ---------------- misc / reporting ----------------
job:
  name: train_gat

report:
  use_deflated_sharpe: true
  seeds: [1, 2, 3]

# ---------------- paths (script can override via CLI) ----------------
paths:
  graph_dir: processed/graphs

# ---------- training ----------
# Single-window path with explicit cut dates (as train.py expects)
split:
  mode: single
  rolling: false
  train_start: "2012-01-31"
  val_start:   "2015-01-30"
  test_start:  "2016-01-29"

# Loss knobs expected by train.py
loss:
  objective: sharpe_rnext       # {"daily_log_utility", "sharpe_rnext", or other=next-step return}
  sharpe_eps: 1.0e-6
  turnover_bps: 10              # transaction cost in basis points per rebalance
  entropy_coef: 1.0e-3
  l1_coef: 1.0e-3

# GAT + Markowitz head settings expected by train.py and model_gat.py
model:
  in_dim: 8
  hidden_dim: 32
  heads: 4
  num_layers: 2
  dropout: 0.10
  use_gatv2: true
  use_edge_attr: true           # use edge_attr from graphs
  head: markowitz               # {"markowitz","direct"}
  weight_cap: 0.02

  # Markowitz layer controls
  markowitz_gamma: 5.0
  markowitz_mode: diag          # {"diag","chol"}
  markowitz_topk: 0             # 0 = use all names
  markowitz_backend: pgd        # {"pgd","cvxpy"}
  markowitz_pgd_steps: 80
  markowitz_normalize_mu: true
  eval_use_cvxpy: false         # use PGD for eval unless you flip this

  # Covariance options used when head == "markowitz"
  cov_method: lw                # {"lw","linear"}
  cov_shrinkage_alpha: 0.10     # only used for "linear"
  cov_ridge_eps: 1.0e-6

# Optional temporal memory block referenced in train.py
temporal:
  use_memory: false
  mem_hidden: null              # or an int, e.g. 16
  decay: 0.90

# Trainer knobs consumed in train.py (not the old 'trainer.*' block)
train:
  out_dir: outputs/gat
  seed: 42
  device: auto                  # {auto, cpu, cuda}
  epochs: 15
  lr: 2.0e-3
  weight_decay: 1.0e-4
  batch_size: 8
  patience: 3                   # early stopping patience (val Sharpe)
  ordered_when_memory: true     # keep chronological order if temporal memory is used

# ---------- rolling windows (consumed by scripts/train_gat.py) ----------
roll:
  enabled: true
  train_months: 36
  val_months: 12
  test_months: 12
  step_months: 12
  # start: "2012-01-31"   # optional bound
  stop:  "2023-12-29"   # optional bound
  # early_stop_patience: 3
  # seeds: [1, 2, 3]


# ---------------- hydra behaviour ----------------
hydra:
  job:
    chdir: false
  run:
    dir: .
  output_subdir: null
